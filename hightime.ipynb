{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8tQJd2YSCfWR"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D7tqLMoKF6uq"
   },
   "source": [
    "HighTime - Web traffic analysis neural model\n",
    "=============\n",
    "<span style=\"color: lightsteelblue;\">Deep Learning</span>\n",
    "\n",
    "The goal of this assignment is to train a simple DNN model to make predictions over web traffic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "MvEblsgEXxrd"
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "from six.moves import range\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us mimic real traffic data by using normal distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5993,
     "status": "ok",
     "timestamp": 1445965582896,
     "user": {
      "color": "#1FA15D",
      "displayName": "Vincent Vanhoucke",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "05076109866853157986",
      "photoUrl": "//lh6.googleusercontent.com/-cCJa7dTDcgQ/AAAAAAAAAAI/AAAAAAAACgw/r2EZ_8oYer4/s50-c-k-no/photo.jpg",
      "sessionId": "6f6f07b359200c46",
      "userId": "102167687554210253930"
     },
     "user_tz": 420
    },
    "id": "RJ-o3UBUFtCw",
    "outputId": "d530534e-0791-4a94-ca6d-1c8f1b908a9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  9  18  21  46  96 150 187 280 331 387 470 505 487 462 430 341 268 184]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAD8CAYAAACW/ATfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nexGRMKCyFxEJAyp7EZEwoLIXEQkD/x9KkLNeCD9MpAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c8b25c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def fake_train(batch_size=24):\n",
    "  assert batch_size > 0 and batch_size < 25\n",
    "  normal = np.random.normal(12, 4, 5000)\n",
    "  train = np.arange(batch_size)\n",
    "\n",
    "  for i in range(0, batch_size):\n",
    "    count = 0\n",
    "    for p in normal:\n",
    "      if (p >= i and p < i + 1):\n",
    "        count += 1\n",
    "    train[i] = count\n",
    "  return train\n",
    "\n",
    "example = fake_train(18)\n",
    "print(example)\n",
    "\n",
    "plt.plot(range(0, 18), example)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lFwoyygOmWsL"
   },
   "source": [
    "Function to generate a training batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 6473,
     "status": "ok",
     "timestamp": 1445965583467,
     "user": {
      "color": "#1FA15D",
      "displayName": "Vincent Vanhoucke",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "05076109866853157986",
      "photoUrl": "//lh6.googleusercontent.com/-cCJa7dTDcgQ/AAAAAAAAAAI/AAAAAAAACgw/r2EZ_8oYer4/s50-c-k-no/photo.jpg",
      "sessionId": "6f6f07b359200c46",
      "userId": "102167687554210253930"
     },
     "user_tz": 420
    },
    "id": "d9wMtjy5hCj9",
    "outputId": "3dd79c80-454a-4be0-8b71-4a4a357b3367"
   },
   "outputs": [],
   "source": [
    "total_seconds = 24 * 3600\n",
    "total_rps = 1000\n",
    "\n",
    "def secs_to_time(time_in_seconds):\n",
    "  hours = time_in_seconds // 3600\n",
    "  minutes = (time_in_seconds - hours * 3600) // 60\n",
    "  seconds = time_in_seconds - hours * 3600 - minutes * 60\n",
    "  return hours, minutes, seconds\n",
    "\n",
    "def time_to_secs(hour, minutes, seconds):\n",
    "  return hour * 3600 + minutes * 60 + seconds\n",
    "\n",
    "def time_to_squashed_secs(hour, minutes, seconds):\n",
    "  return time_to_secs(hour, minutes, seconds) / total_seconds\n",
    "\n",
    "def secs_to_string(sec):\n",
    "  result = ':'.join([('%d' % i) for i in secs_to_time(sec)])\n",
    "  return result + (' (%dth second)' % sec)\n",
    "\n",
    "def squashed_secs_to_string(sq_sec):\n",
    "  return secs_to_string(sq_sec * total_seconds)\n",
    "\n",
    "def squashed_label_to_label(sq_label):\n",
    "  return sq_label * total_rps\n",
    "\n",
    "class BatchGenerator(object):\n",
    "  def __init__(self, batch_size):\n",
    "    self._batch_size = batch_size\n",
    "\n",
    "  def spit(self):\n",
    "    labels = fake_train(self._batch_size).reshape(self._batch_size, 1)\n",
    "    train = []\n",
    "\n",
    "    for hour in range(self._batch_size):\n",
    "      minutes = random.randint(0, 59)\n",
    "      seconds = random.randint(0, 59)\n",
    "      train.append(time_to_squashed_secs(hour, minutes, seconds))\n",
    "\n",
    "    return np.array(train, dtype=np.float32).reshape(self._batch_size, 1), (labels / total_rps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate valid and test datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time 0:58:41 (3521th second) => 9.00 rps\n",
      "Time 1:54:17 (6857th second) => 13.00 rps\n",
      "Time 2:18:15 (8295th second) => 27.00 rps\n",
      "Time 3:25:14 (12314th second) => 60.00 rps\n",
      "Time 4:56:33 (17793th second) => 86.00 rps\n",
      "Time 5:53:24 (21204th second) => 109.00 rps\n",
      "Time 6:17:42 (22662th second) => 175.00 rps\n",
      "Time 7:0:2 (25202th second) => 291.00 rps\n",
      "Time 8:43:29 (31409th second) => 332.00 rps\n",
      "Time 9:24:17 (33857th second) => 413.00 rps\n",
      "Time 10:22:57 (37377th second) => 497.00 rps\n",
      "Time 11:52:25 (42745th second) => 439.00 rps\n",
      "Time 12:16:42 (44202th second) => 495.00 rps\n",
      "Time 13:28:47 (48527th second) => 513.00 rps\n",
      "Time 14:11:29 (51089th second) => 385.00 rps\n",
      "Time 15:30:42 (55842th second) => 346.00 rps\n",
      "Time 16:11:37 (58297th second) => 268.00 rps\n",
      "Time 17:6:47 (61607th second) => 186.00 rps\n",
      "Time 18:22:31 (66151th second) => 138.00 rps\n",
      "Time 19:53:54 (71634th second) => 96.00 rps\n",
      "Time 20:32:24 (73944th second) => 56.00 rps\n",
      "Time 21:58:10 (79090th second) => 28.00 rps\n",
      "Time 22:58:50 (82730th second) => 16.00 rps\n",
      "Time 23:58:2 (86282th second) => 8.00 rps\n"
     ]
    }
   ],
   "source": [
    "generator = BatchGenerator(24)\n",
    "\n",
    "test_dataset, test_labels = generator.spit()\n",
    "\n",
    "# print(test_dataset)\n",
    "# print(test_labels)\n",
    "\n",
    "for sec, label in list(zip(test_dataset, test_labels)):\n",
    "  print('Time %s => %03.2f rps' % (squashed_secs_to_string(sec), squashed_label_to_label(label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K8f67YXaDr4C"
   },
   "source": [
    "Simple NN Model with one hidden layer and hyperbolic tangent activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Q5rxZK6RDuGe"
   },
   "outputs": [],
   "source": [
    "feature_size = 1 # number of features to feed input\n",
    "num_labels = 1 # number of output labels\n",
    "num_hidden_nodes = 2\n",
    "batch_size = 24\n",
    "learning_rate = 0.05\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "  # Input data. For the training data, we use a placeholder that will be fed\n",
    "  # at run time with a training minibatch.\n",
    "  X = tf.placeholder(tf.float32, shape=(batch_size, feature_size))\n",
    "  Y = tf.placeholder(tf.float32, shape=(batch_size, 1))\n",
    "\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  predict_data = tf.placeholder(tf.float32, shape=(1, feature_size))\n",
    "\n",
    "  # Hidden layer variables\n",
    "  weights1 = tf.Variable(tf.ones([feature_size, num_hidden_nodes]))\n",
    "  biases1 = tf.Variable(tf.zeros([num_hidden_nodes]))\n",
    "\n",
    "  # Variables.\n",
    "  weights2 = tf.Variable(tf.ones([num_hidden_nodes, num_labels]))\n",
    "  biases2 = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "  # Training computation.\n",
    "  o = tf.matmul(X, weights1) + biases1\n",
    "  hidden_layer = tf.tan(o)\n",
    "\n",
    "  y = tf.matmul(hidden_layer, weights2) + biases2\n",
    "  error = y - Y\n",
    "  sq_error = tf.square(error)\n",
    "  loss = tf.reduce_mean(sq_error)\n",
    "\n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "  # Predictions for the training, test and real data.\n",
    "#   train_prediction = y\n",
    "#   test_prediction_hidden = tf.nn.sigmoid(tf.matmul(tf_test_dataset, weights1) + biases1)\n",
    "#   test_prediction = tf.matmul(test_prediction_hidden, weights2) + biases2\n",
    "  prediction_hidden = tf.tan(tf.matmul(predict_data, weights1) + biases1)\n",
    "  prediction = tf.matmul(prediction_hidden, weights2) + biases2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.759  0.371  0.238 -0.186]\n",
      "[ 0.681  0.592  0.559  0.454]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([0.759, 0.371, 0.2378, -0.1861], np.float32)\n",
    "print(a)\n",
    "\n",
    "sigma = tf.nn.sigmoid(a).eval(session=tf.Session())\n",
    "print(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 1.806150\n",
      "w2: [[ 0.902]\n",
      " [ 0.902]]\n",
      "Minibatch loss at step 10: 0.168694\n",
      "w2: [[ 0.808]\n",
      " [ 0.808]]\n",
      "Minibatch loss at step 20: 0.122918\n",
      "w2: [[ 0.749]\n",
      " [ 0.749]]\n",
      "Minibatch loss at step 30: 0.093781\n",
      "w2: [[ 0.703]\n",
      " [ 0.703]]\n",
      "Minibatch loss at step 40: 0.080726\n",
      "w2: [[ 0.667]\n",
      " [ 0.667]]\n",
      "Minibatch loss at step 50: 0.070243\n",
      "w2: [[ 0.637]\n",
      " [ 0.637]]\n",
      "Minibatch loss at step 60: 0.060039\n",
      "w2: [[ 0.613]\n",
      " [ 0.613]]\n",
      "Minibatch loss at step 70: 0.055923\n",
      "w2: [[ 0.591]\n",
      " [ 0.591]]\n",
      "Minibatch loss at step 80: 0.054337\n",
      "w2: [[ 0.573]\n",
      " [ 0.573]]\n",
      "Minibatch loss at step 90: 0.047169\n",
      "w2: [[ 0.557]\n",
      " [ 0.557]]\n",
      "Minibatch loss at step 100: 0.045073\n",
      "w2: [[ 0.543]\n",
      " [ 0.543]]\n",
      "Minibatch loss at step 110: 0.042375\n",
      "w2: [[ 0.530]\n",
      " [ 0.530]]\n",
      "Minibatch loss at step 120: 0.042189\n",
      "w2: [[ 0.519]\n",
      " [ 0.519]]\n",
      "Minibatch loss at step 130: 0.039572\n",
      "w2: [[ 0.509]\n",
      " [ 0.509]]\n",
      "Minibatch loss at step 140: 0.038591\n",
      "w2: [[ 0.500]\n",
      " [ 0.500]]\n",
      "Minibatch loss at step 150: 0.036589\n",
      "w2: [[ 0.491]\n",
      " [ 0.491]]\n",
      "Minibatch loss at step 160: 0.037587\n",
      "w2: [[ 0.484]\n",
      " [ 0.484]]\n",
      "Minibatch loss at step 170: 0.037153\n",
      "w2: [[ 0.477]\n",
      " [ 0.477]]\n",
      "Minibatch loss at step 180: 0.036728\n",
      "w2: [[ 0.471]\n",
      " [ 0.471]]\n",
      "Minibatch loss at step 190: 0.036014\n",
      "w2: [[ 0.465]\n",
      " [ 0.465]]\n",
      "Minibatch loss at step 200: 0.036187\n",
      "w2: [[ 0.459]\n",
      " [ 0.459]]\n",
      "Minibatch loss at step 210: 0.035673\n",
      "w2: [[ 0.455]\n",
      " [ 0.455]]\n",
      "Minibatch loss at step 220: 0.034833\n",
      "w2: [[ 0.450]\n",
      " [ 0.450]]\n",
      "Minibatch loss at step 230: 0.034381\n",
      "w2: [[ 0.446]\n",
      " [ 0.446]]\n",
      "Minibatch loss at step 240: 0.034321\n",
      "w2: [[ 0.442]\n",
      " [ 0.442]]\n",
      "Minibatch loss at step 250: 0.032797\n",
      "w2: [[ 0.438]\n",
      " [ 0.438]]\n",
      "Minibatch loss at step 260: 0.032905\n",
      "w2: [[ 0.434]\n",
      " [ 0.434]]\n",
      "Minibatch loss at step 270: 0.034454\n",
      "w2: [[ 0.431]\n",
      " [ 0.431]]\n",
      "Minibatch loss at step 280: 0.032531\n",
      "w2: [[ 0.428]\n",
      " [ 0.428]]\n",
      "Minibatch loss at step 290: 0.034638\n",
      "w2: [[ 0.425]\n",
      " [ 0.425]]\n",
      "Minibatch loss at step 300: 0.033533\n",
      "w2: [[ 0.422]\n",
      " [ 0.422]]\n",
      "Minibatch loss at step 310: 0.033916\n",
      "w2: [[ 0.420]\n",
      " [ 0.420]]\n"
     ]
    }
   ],
   "source": [
    "num_steps = 311\n",
    "generator = BatchGenerator(batch_size)\n",
    "\n",
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels))\n",
    "          / predictions.shape[0])\n",
    "\n",
    "session = tf.Session(graph=graph)\n",
    "\n",
    "with graph.as_default():\n",
    "  with session.as_default():\n",
    "    tf.global_variables_initializer().run()\n",
    "    print(\"Initialized\")\n",
    "    for step in range(num_steps):\n",
    "      batch_data, batch_labels = generator.spit()\n",
    "      feed_dict = {X : batch_data, Y : batch_labels}\n",
    "      _, l, w2e = session.run(\n",
    "        [optimizer, loss, weights2], feed_dict=feed_dict)\n",
    "      if (step % 10 == 0):\n",
    "        print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "#         print(\"output: %s\" % (oe))\n",
    "#         print(\"hidden layer %s\" % (hl))\n",
    "#         print(\"X: %s\" % (Xe))\n",
    "#         print(\"Y: %s\" % (Ye))\n",
    "#         print(\"w1: %s\" % (w1e))\n",
    "#         print(\"bias1: %s\" % (b1e))\n",
    "#         print(\"y: %s\" % (ye))\n",
    "        print(\"w2: %s\" % (w2e))\n",
    "#         print(\"bias2: %s\" % (b2e))\n",
    "#         print(\"error: %s\" % (ee))\n",
    "#         print(\"squared error: %s\" % (see))\n",
    "\n",
    "  #         print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "    #       print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "    #         valid_prediction.eval(), valid_labels))\n",
    "  #         print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We want to predict rps at 1:0:0 (3600th second)\n",
      "[[ 134.804]]\n"
     ]
    }
   ],
   "source": [
    "to_predict = time_to_squashed_secs(1, 0, 0)\n",
    "print('We want to predict rps at %s' % squashed_secs_to_string(to_predict))\n",
    "data_to_predict = np.array([to_predict]).reshape(1, feature_size)\n",
    "\n",
    "with session.as_default():\n",
    "  predicted = prediction.eval(feed_dict={predict_data : data_to_predict})\n",
    "  print(squashed_label_to_label(predicted))\n",
    "#   print(weights1.eval())\n",
    "#   print(biases1.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 41
      },
      {
       "item_id": 80
      },
      {
       "item_id": 126
      },
      {
       "item_id": 144
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 199909,
     "status": "ok",
     "timestamp": 1445965877333,
     "user": {
      "color": "#1FA15D",
      "displayName": "Vincent Vanhoucke",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "05076109866853157986",
      "photoUrl": "//lh6.googleusercontent.com/-cCJa7dTDcgQ/AAAAAAAAAAI/AAAAAAAACgw/r2EZ_8oYer4/s50-c-k-no/photo.jpg",
      "sessionId": "6f6f07b359200c46",
      "userId": "102167687554210253930"
     },
     "user_tz": 420
    },
    "id": "RD9zQCZTEaEm",
    "outputId": "5e868466-2532-4545-ce35-b403cf5d9de6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 0.003011\n",
      "Minibatch loss at step 10: 0.002587\n",
      "Minibatch loss at step 20: 0.002387\n",
      "Minibatch loss at step 30: 0.003445\n"
     ]
    }
   ],
   "source": [
    "num_steps = 31\n",
    "generator = BatchGenerator(24)\n",
    "\n",
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels))\n",
    "          / predictions.shape[0])\n",
    "\n",
    "session = tf.Session(graph=graph)\n",
    "\n",
    "with graph.as_default():\n",
    "  with session.as_default():\n",
    "    tf.global_variables_initializer().run()\n",
    "    print(\"Initialized\")\n",
    "    for step in range(num_steps):\n",
    "      for batch in np.array(generator.spit()).reshape(2, 24).T:\n",
    "#         np.set_printoptions(formatter={'float': '{: 0.3f}'.format})\n",
    "#         print(batch)\n",
    "\n",
    "        batch_data, batch_labels = np.array(batch).reshape(2, 1, 1)\n",
    "  #       batch_data, batch_labels = generator.spit()\n",
    "\n",
    "#         print(batch.reshape(2, 24))\n",
    "#         print(batch_data.shape, batch_labels.shape)\n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it.\n",
    "        feed_dict = {X : batch_data, Y : batch_labels}\n",
    "        _, l = session.run(\n",
    "          [optimizer, loss], feed_dict=feed_dict)\n",
    "      if (step % 10 == 0):\n",
    "        print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "#         print(\"output: %s\" % (oe))\n",
    "#         print(\"hidden layer %s\" % (hl))\n",
    "#         print(\"X: %s\" % (Xe))\n",
    "#         print(\"Y: %s\" % (Ye))\n",
    "#         print(\"w1: %s\" % (w1e))\n",
    "#         print(\"bias1: %s\" % (b1e))\n",
    "#         print(\"y: %s\" % (ye))\n",
    "#         print(\"w2: %s\" % (w2e))\n",
    "#         print(\"bias2: %s\" % (b2e))\n",
    "#         print(\"error: %s\" % (ee))\n",
    "#         print(\"squared error: %s\" % (see))\n",
    "\n",
    "  #         print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "    #       print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "    #         valid_prediction.eval(), valid_labels))\n",
    "  #         print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let us check it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We want to predict rps at 1:0:0 (3600th second)\n",
      "[[ 336.656]]\n"
     ]
    }
   ],
   "source": [
    "to_predict = time_to_squashed_secs(1, 0, 0)\n",
    "print('We want to predict rps at %s' % squashed_secs_to_string(to_predict))\n",
    "data_to_predict = np.array([to_predict]).reshape(1, feature_size)\n",
    "\n",
    "with session.as_default():\n",
    "  predicted = prediction.eval(feed_dict={predict_data : data_to_predict})\n",
    "  print(squashed_label_to_label(predicted))\n",
    "#   print(weights1.eval())\n",
    "#   print(biases1.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "6_lstm.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
